{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing Packages needed and Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T17:56:14.919326Z",
     "iopub.status.busy": "2023-11-13T17:56:14.918928Z",
     "iopub.status.idle": "2023-11-13T17:56:23.541091Z",
     "shell.execute_reply": "2023-11-13T17:56:23.540095Z",
     "shell.execute_reply.started": "2023-11-13T17:56:14.919244Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install openpyxl  --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T17:59:36.454331Z",
     "iopub.status.busy": "2023-11-13T17:59:36.453974Z",
     "iopub.status.idle": "2023-11-13T17:59:41.937671Z",
     "shell.execute_reply": "2023-11-13T17:59:41.936882Z",
     "shell.execute_reply.started": "2023-11-13T17:59:36.454296Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T19:56:45.541906Z",
     "iopub.status.busy": "2023-11-13T19:56:45.541566Z",
     "iopub.status.idle": "2023-11-13T19:56:45.546074Z",
     "shell.execute_reply": "2023-11-13T19:56:45.545078Z",
     "shell.execute_reply.started": "2023-11-13T19:56:45.541878Z"
    }
   },
   "outputs": [],
   "source": [
    "ENCODER_LEN = 140\n",
    "DECODER_LEN = 40\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = BATCH_SIZE*8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "After creating the dataframe we apply Start of Sentence(<SOS>) and End of Sentence(<EOS>) tokens. \n",
    "These sentences are then tokenized and padded to fix length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T19:57:11.568107Z",
     "iopub.status.busy": "2023-11-13T19:57:11.567711Z",
     "iopub.status.idle": "2023-11-13T19:57:21.201659Z",
     "shell.execute_reply": "2023-11-13T19:57:21.200725Z",
     "shell.execute_reply.started": "2023-11-13T19:57:11.568072Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Short</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4 ex-bank officials booked for cheating bank o...</td>\n",
       "      <td>The CBI on Saturday booked four former officia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Supreme Court to go paperless in 6 months: CJI</td>\n",
       "      <td>Chief Justice JS Khehar has said the Supreme C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>At least 3 killed, 30 injured in blast in Sylh...</td>\n",
       "      <td>At least three people were killed, including a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why has Reliance been barred from trading in f...</td>\n",
       "      <td>Mukesh Ambani-led Reliance Industries (RIL) wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Was stopped from entering my own studio at Tim...</td>\n",
       "      <td>TV news anchor Arnab Goswami has said he was t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  \\\n",
       "0  4 ex-bank officials booked for cheating bank o...   \n",
       "1     Supreme Court to go paperless in 6 months: CJI   \n",
       "2  At least 3 killed, 30 injured in blast in Sylh...   \n",
       "3  Why has Reliance been barred from trading in f...   \n",
       "4  Was stopped from entering my own studio at Tim...   \n",
       "\n",
       "                                               Short  \n",
       "0  The CBI on Saturday booked four former officia...  \n",
       "1  Chief Justice JS Khehar has said the Supreme C...  \n",
       "2  At least three people were killed, including a...  \n",
       "3  Mukesh Ambani-led Reliance Industries (RIL) wa...  \n",
       "4  TV news anchor Arnab Goswami has said he was t...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = pd.read_excel(\"../input/inshorts-news-data/Inshorts Cleaned Data.xlsx\",engine = 'openpyxl')\n",
    "news.drop(['Source ', 'Time ', 'Publish Date'], axis=1, inplace=True)\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T19:57:21.203207Z",
     "iopub.status.busy": "2023-11-13T19:57:21.202932Z",
     "iopub.status.idle": "2023-11-13T19:57:21.208128Z",
     "shell.execute_reply": "2023-11-13T19:57:21.207228Z",
     "shell.execute_reply.started": "2023-11-13T19:57:21.203181Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55104, 2)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T19:57:21.210197Z",
     "iopub.status.busy": "2023-11-13T19:57:21.209847Z",
     "iopub.status.idle": "2023-11-13T19:57:21.307022Z",
     "shell.execute_reply": "2023-11-13T19:57:21.306267Z",
     "shell.execute_reply.started": "2023-11-13T19:57:21.210168Z"
    }
   },
   "outputs": [],
   "source": [
    "article = news['Short']\n",
    "summary = news['Headline']\n",
    "article = article.apply(lambda x: '<SOS> ' + x + ' <EOS>')\n",
    "summary = summary.apply(lambda x: '<SOS> ' + x + ' <EOS>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T19:57:21.308964Z",
     "iopub.status.busy": "2023-11-13T19:57:21.308602Z",
     "iopub.status.idle": "2023-11-13T19:57:21.623442Z",
     "shell.execute_reply": "2023-11-13T19:57:21.622488Z",
     "shell.execute_reply.started": "2023-11-13T19:57:21.308926Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = re.sub(r\"&.[1-9]+;\",\" \",text)\n",
    "    return text\n",
    "article = article.apply(lambda x: preprocess(x))\n",
    "summary = summary.apply(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T19:57:34.228976Z",
     "iopub.status.busy": "2023-11-13T19:57:34.228631Z",
     "iopub.status.idle": "2023-11-13T19:57:43.383404Z",
     "shell.execute_reply": "2023-11-13T19:57:43.382642Z",
     "shell.execute_reply.started": "2023-11-13T19:57:34.228946Z"
    }
   },
   "outputs": [],
   "source": [
    "filters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'\n",
    "oov_token = '<unk>'\n",
    "article_tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token=oov_token)\n",
    "summary_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters, oov_token=oov_token)\n",
    "article_tokenizer.fit_on_texts(article)\n",
    "summary_tokenizer.fit_on_texts(summary)\n",
    "inputs = article_tokenizer.texts_to_sequences(article)\n",
    "targets = summary_tokenizer.texts_to_sequences(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T19:57:43.384954Z",
     "iopub.status.busy": "2023-11-13T19:57:43.384690Z",
     "iopub.status.idle": "2023-11-13T19:57:43.390038Z",
     "shell.execute_reply": "2023-11-13T19:57:43.389169Z",
     "shell.execute_reply.started": "2023-11-13T19:57:43.384928Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76362 29661\n"
     ]
    }
   ],
   "source": [
    "ENCODER_VOCAB = len(article_tokenizer.word_index) + 1\n",
    "DECODER_VOCAB = len(summary_tokenizer.word_index) + 1\n",
    "print(ENCODER_VOCAB, DECODER_VOCAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T19:57:43.392104Z",
     "iopub.status.busy": "2023-11-13T19:57:43.391735Z",
     "iopub.status.idle": "2023-11-13T19:57:44.855217Z",
     "shell.execute_reply": "2023-11-13T19:57:44.854231Z",
     "shell.execute_reply.started": "2023-11-13T19:57:43.392074Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs, maxlen=ENCODER_LEN, padding='post', truncating='post')\n",
    "targets = tf.keras.preprocessing.sequence.pad_sequences(targets, maxlen=DECODER_LEN, padding='post', truncating='post')\n",
    "inputs = tf.cast(inputs, dtype=tf.int64)\n",
    "targets = tf.cast(targets, dtype=tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T19:57:44.857129Z",
     "iopub.status.busy": "2023-11-13T19:57:44.856826Z",
     "iopub.status.idle": "2023-11-13T19:57:44.917952Z",
     "shell.execute_reply": "2023-11-13T19:57:44.917069Z",
     "shell.execute_reply.started": "2023-11-13T19:57:44.857099Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((inputs, targets)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Model\n",
    "\n",
    "The next several blocks of code contain the vanilla Transformer model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T19:57:44.919369Z",
     "iopub.status.busy": "2023-11-13T19:57:44.919108Z",
     "iopub.status.idle": "2023-11-13T19:57:44.931253Z",
     "shell.execute_reply": "2023-11-13T19:57:44.930370Z",
     "shell.execute_reply.started": "2023-11-13T19:57:44.919344Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_angles(position, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "    return position * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(\n",
    "        np.arange(position)[:, np.newaxis],\n",
    "        np.arange(d_model)[np.newaxis, :],\n",
    "        d_model\n",
    "    )\n",
    "\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask\n",
    "\n",
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)\n",
    "    return output, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T19:57:44.932655Z",
     "iopub.status.busy": "2023-11-13T19:57:44.932384Z",
     "iopub.status.idle": "2023-11-13T19:57:44.947145Z",
     "shell.execute_reply": "2023-11-13T19:57:44.946286Z",
     "shell.execute_reply.started": "2023-11-13T19:57:44.932617Z"
    }
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)\n",
    "        k = self.wk(k)\n",
    "        v = self.wv(v)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "        \n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
    "        output = self.dense(concat_attention)\n",
    "            \n",
    "        return output, attention_weights\n",
    "    \n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'),\n",
    "        tf.keras.layers.Dense(d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T19:57:44.948845Z",
     "iopub.status.busy": "2023-11-13T19:57:44.948478Z",
     "iopub.status.idle": "2023-11-13T19:57:44.960332Z",
     "shell.execute_reply": "2023-11-13T19:57:44.959495Z",
     "shell.execute_reply.started": "2023-11-13T19:57:44.948800Z"
    }
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, training, mask):\n",
    "        attn_output, _ = self.mha(x, x, x, mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T19:57:44.962527Z",
     "iopub.status.busy": "2023-11-13T19:57:44.962271Z",
     "iopub.status.idle": "2023-11-13T19:57:44.974293Z",
     "shell.execute_reply": "2023-11-13T19:57:44.973248Z",
     "shell.execute_reply.started": "2023-11-13T19:57:44.962502Z"
    }
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)\n",
    "\n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T19:57:44.976102Z",
     "iopub.status.busy": "2023-11-13T19:57:44.975788Z",
     "iopub.status.idle": "2023-11-13T19:57:44.992798Z",
     "shell.execute_reply": "2023-11-13T19:57:44.991929Z",
     "shell.execute_reply.started": "2023-11-13T19:57:44.976062Z"
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "    \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "    \n",
    "        return x\n",
    "    \n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "        \n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "    \n",
    "        return x, attention_weights\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T19:57:44.994158Z",
     "iopub.status.busy": "2023-11-13T19:57:44.993796Z",
     "iopub.status.idle": "2023-11-13T19:57:45.005779Z",
     "shell.execute_reply": "2023-11-13T19:57:45.005076Z",
     "shell.execute_reply.started": "2023-11-13T19:57:44.994130Z"
    }
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask)\n",
    "\n",
    "        dec_output, attention_weights = self.decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)\n",
    "\n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T19:57:57.461119Z",
     "iopub.status.busy": "2023-11-13T19:57:57.460748Z",
     "iopub.status.idle": "2023-11-13T19:57:57.465261Z",
     "shell.execute_reply": "2023-11-13T19:57:57.464399Z",
     "shell.execute_reply.started": "2023-11-13T19:57:57.461085Z"
    }
   },
   "outputs": [],
   "source": [
    "num_layers = 6\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "dropout_rate = 0.3\n",
    "EPOCHS = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T19:58:01.018387Z",
     "iopub.status.busy": "2023-11-13T19:58:01.018026Z",
     "iopub.status.idle": "2023-11-13T19:58:01.024975Z",
     "shell.execute_reply": "2023-11-13T19:58:01.024081Z",
     "shell.execute_reply.started": "2023-11-13T19:58:01.018355Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T19:58:01.407810Z",
     "iopub.status.busy": "2023-11-13T19:58:01.407479Z",
     "iopub.status.idle": "2023-11-13T19:58:01.412652Z",
     "shell.execute_reply": "2023-11-13T19:58:01.411733Z",
     "shell.execute_reply.started": "2023-11-13T19:58:01.407782Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T19:58:02.132999Z",
     "iopub.status.busy": "2023-11-13T19:58:02.132639Z",
     "iopub.status.idle": "2023-11-13T19:58:02.298604Z",
     "shell.execute_reply": "2023-11-13T19:58:02.297705Z",
     "shell.execute_reply.started": "2023-11-13T19:58:02.132956Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Loss and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T19:58:03.650222Z",
     "iopub.status.busy": "2023-11-13T19:58:03.649838Z",
     "iopub.status.idle": "2023-11-13T19:58:03.659415Z",
     "shell.execute_reply": "2023-11-13T19:58:03.658114Z",
     "shell.execute_reply.started": "2023-11-13T19:58:03.650188Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "\n",
    "\n",
    "def accuracy_function(real, pred):\n",
    "    accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
    "    #accuracies = tf.cast(accuracies, dtype= tf.float32)\n",
    "\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    accuracies = tf.math.logical_and(mask, accuracies)\n",
    "\n",
    "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T19:58:04.187757Z",
     "iopub.status.busy": "2023-11-13T19:58:04.187319Z",
     "iopub.status.idle": "2023-11-13T19:58:04.207429Z",
     "shell.execute_reply": "2023-11-13T19:58:04.206562Z",
     "shell.execute_reply.started": "2023-11-13T19:58:04.187718Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T19:58:04.586350Z",
     "iopub.status.busy": "2023-11-13T19:58:04.585980Z",
     "iopub.status.idle": "2023-11-13T19:58:04.759318Z",
     "shell.execute_reply": "2023-11-13T19:58:04.758232Z",
     "shell.execute_reply.started": "2023-11-13T19:58:04.586315Z"
    }
   },
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=ENCODER_VOCAB,\n",
    "    target_vocab_size=DECODER_VOCAB,\n",
    "    pe_input=1000,\n",
    "    pe_target=1000,\n",
    "    rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T19:58:06.307161Z",
     "iopub.status.busy": "2023-11-13T19:58:06.306795Z",
     "iopub.status.idle": "2023-11-13T19:58:06.312249Z",
     "shell.execute_reply": "2023-11-13T19:58:06.311304Z",
     "shell.execute_reply.started": "2023-11-13T19:58:06.307127Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T19:58:06.902857Z",
     "iopub.status.busy": "2023-11-13T19:58:06.902495Z",
     "iopub.status.idle": "2023-11-13T19:58:06.962902Z",
     "shell.execute_reply": "2023-11-13T19:58:06.962053Z",
     "shell.execute_reply.started": "2023-11-13T19:58:06.902823Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest checkpoint restored!!\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"checkpoints\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T19:58:09.873602Z",
     "iopub.status.busy": "2023-11-13T19:58:09.873238Z",
     "iopub.status.idle": "2023-11-13T19:58:10.269117Z",
     "shell.execute_reply": "2023-11-13T19:58:10.268213Z",
     "shell.execute_reply.started": "2023-11-13T19:58:09.873569Z"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(\n",
    "            inp, tar_inp, \n",
    "            True, \n",
    "            enc_padding_mask, \n",
    "            combined_mask, \n",
    "            dec_padding_mask\n",
    "        )\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(accuracy_function(tar_real, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T19:58:11.124562Z",
     "iopub.status.busy": "2023-11-13T19:58:11.124116Z",
     "iopub.status.idle": "2023-11-13T23:16:57.667130Z",
     "shell.execute_reply": "2023-11-13T23:16:57.666162Z",
     "shell.execute_reply.started": "2023-11-13T19:58:11.124518Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 9.3086 Accuracy 0.0116\n",
      "Epoch 1 Batch 100 Loss 7.9107 Accuracy 0.0876\n",
      "Epoch 1 Batch 200 Loss 7.6066 Accuracy 0.0969\n",
      "Epoch 1 Batch 300 Loss 7.3448 Accuracy 0.1086\n",
      "Epoch 1 Batch 400 Loss 7.1488 Accuracy 0.1181\n",
      "Epoch 1 Batch 500 Loss 6.9802 Accuracy 0.1280\n",
      "Epoch 1 Batch 600 Loss 6.8374 Accuracy 0.1372\n",
      "Epoch 1 Batch 700 Loss 6.7076 Accuracy 0.1457\n",
      "Epoch 1 Batch 800 Loss 6.5871 Accuracy 0.1533\n",
      "Epoch 1 Loss 6.5183 Accuracy 0.1577\n",
      "Time taken for 1 epoch: 211.00184273719788 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 6.2362 Accuracy 0.1577\n",
      "Epoch 2 Batch 100 Loss 5.9565 Accuracy 0.1592\n",
      "Epoch 2 Batch 200 Loss 5.8627 Accuracy 0.1612\n",
      "Epoch 2 Batch 300 Loss 5.7741 Accuracy 0.1636\n",
      "Epoch 2 Batch 400 Loss 5.7136 Accuracy 0.1664\n",
      "Epoch 2 Batch 500 Loss 5.6383 Accuracy 0.1705\n",
      "Epoch 2 Batch 600 Loss 5.5601 Accuracy 0.1754\n",
      "Epoch 2 Batch 700 Loss 5.4856 Accuracy 0.1804\n",
      "Epoch 2 Batch 800 Loss 5.4129 Accuracy 0.1856\n",
      "Epoch 2 Loss 5.3686 Accuracy 0.1888\n",
      "Time taken for 1 epoch: 198.13903665542603 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 5.6299 Accuracy 0.1888\n",
      "Epoch 3 Batch 100 Loss 5.2684 Accuracy 0.1902\n",
      "Epoch 3 Batch 200 Loss 5.1909 Accuracy 0.1920\n",
      "Epoch 3 Batch 300 Loss 5.1153 Accuracy 0.1943\n",
      "Epoch 3 Batch 400 Loss 5.0682 Accuracy 0.1967\n",
      "Epoch 3 Batch 500 Loss 5.0054 Accuracy 0.1999\n",
      "Epoch 3 Batch 600 Loss 4.9375 Accuracy 0.2037\n",
      "Epoch 3 Batch 700 Loss 4.8712 Accuracy 0.2077\n",
      "Epoch 3 Batch 800 Loss 4.8120 Accuracy 0.2118\n",
      "Epoch 3 Loss 4.7759 Accuracy 0.2143\n",
      "Time taken for 1 epoch: 198.075453042984 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 5.2319 Accuracy 0.2143\n",
      "Epoch 4 Batch 100 Loss 4.8474 Accuracy 0.2155\n",
      "Epoch 4 Batch 200 Loss 4.7548 Accuracy 0.2172\n",
      "Epoch 4 Batch 300 Loss 4.6894 Accuracy 0.2191\n",
      "Epoch 4 Batch 400 Loss 4.6418 Accuracy 0.2212\n",
      "Epoch 4 Batch 500 Loss 4.5750 Accuracy 0.2241\n",
      "Epoch 4 Batch 600 Loss 4.5069 Accuracy 0.2274\n",
      "Epoch 4 Batch 700 Loss 4.4430 Accuracy 0.2309\n",
      "Epoch 4 Batch 800 Loss 4.3859 Accuracy 0.2345\n",
      "Epoch 4 Loss 4.3513 Accuracy 0.2367\n",
      "Time taken for 1 epoch: 197.85781407356262 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 4.8407 Accuracy 0.2367\n",
      "Epoch 5 Batch 100 Loss 4.4602 Accuracy 0.2381\n",
      "Epoch 5 Batch 200 Loss 4.3860 Accuracy 0.2397\n",
      "Epoch 5 Batch 300 Loss 4.3189 Accuracy 0.2416\n",
      "Epoch 5 Batch 400 Loss 4.2778 Accuracy 0.2436\n",
      "Epoch 5 Batch 500 Loss 4.2118 Accuracy 0.2464\n",
      "Epoch 5 Batch 600 Loss 4.1469 Accuracy 0.2494\n",
      "Epoch 5 Batch 700 Loss 4.0863 Accuracy 0.2526\n",
      "Epoch 5 Batch 800 Loss 4.0326 Accuracy 0.2559\n",
      "Saving checkpoint for epoch 5 at checkpoints/ckpt-15\n",
      "Epoch 5 Loss 4.0035 Accuracy 0.2579\n",
      "Time taken for 1 epoch: 198.93283987045288 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 4.5671 Accuracy 0.2580\n",
      "Epoch 6 Batch 100 Loss 4.1724 Accuracy 0.2593\n",
      "Epoch 6 Batch 200 Loss 4.1040 Accuracy 0.2608\n",
      "Epoch 6 Batch 300 Loss 4.0439 Accuracy 0.2626\n",
      "Epoch 6 Batch 400 Loss 4.0015 Accuracy 0.2646\n",
      "Epoch 6 Batch 500 Loss 3.9373 Accuracy 0.2671\n",
      "Epoch 6 Batch 600 Loss 3.8718 Accuracy 0.2698\n",
      "Epoch 6 Batch 700 Loss 3.8122 Accuracy 0.2728\n",
      "Epoch 6 Batch 800 Loss 3.7608 Accuracy 0.2758\n",
      "Epoch 6 Loss 3.7306 Accuracy 0.2777\n",
      "Time taken for 1 epoch: 198.04907202720642 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 4.0225 Accuracy 0.2777\n",
      "Epoch 7 Batch 100 Loss 3.9253 Accuracy 0.2790\n",
      "Epoch 7 Batch 200 Loss 3.8502 Accuracy 0.2805\n",
      "Epoch 7 Batch 300 Loss 3.7886 Accuracy 0.2823\n",
      "Epoch 7 Batch 400 Loss 3.7401 Accuracy 0.2843\n",
      "Epoch 7 Batch 500 Loss 3.6749 Accuracy 0.2867\n",
      "Epoch 7 Batch 600 Loss 3.6075 Accuracy 0.2894\n",
      "Epoch 7 Batch 700 Loss 3.5482 Accuracy 0.2923\n",
      "Epoch 7 Batch 800 Loss 3.4955 Accuracy 0.2952\n",
      "Epoch 7 Loss 3.4660 Accuracy 0.2970\n",
      "Time taken for 1 epoch: 198.13575100898743 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 4.0121 Accuracy 0.2970\n",
      "Epoch 8 Batch 100 Loss 3.6195 Accuracy 0.2985\n",
      "Epoch 8 Batch 200 Loss 3.5361 Accuracy 0.3003\n",
      "Epoch 8 Batch 300 Loss 3.4591 Accuracy 0.3023\n",
      "Epoch 8 Batch 400 Loss 3.4019 Accuracy 0.3045\n",
      "Epoch 8 Batch 500 Loss 3.3241 Accuracy 0.3073\n",
      "Epoch 8 Batch 600 Loss 3.2499 Accuracy 0.3103\n",
      "Epoch 8 Batch 700 Loss 3.1865 Accuracy 0.3134\n",
      "Epoch 8 Batch 800 Loss 3.1265 Accuracy 0.3167\n",
      "Epoch 8 Loss 3.0937 Accuracy 0.3187\n",
      "Time taken for 1 epoch: 197.73337626457214 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 3.6445 Accuracy 0.3187\n",
      "Epoch 9 Batch 100 Loss 3.1578 Accuracy 0.3207\n",
      "Epoch 9 Batch 200 Loss 3.0753 Accuracy 0.3230\n",
      "Epoch 9 Batch 300 Loss 2.9965 Accuracy 0.3255\n",
      "Epoch 9 Batch 400 Loss 2.9386 Accuracy 0.3282\n",
      "Epoch 9 Batch 500 Loss 2.8698 Accuracy 0.3313\n",
      "Epoch 9 Batch 600 Loss 2.8027 Accuracy 0.3346\n",
      "Epoch 9 Batch 700 Loss 2.7422 Accuracy 0.3380\n",
      "Epoch 9 Batch 800 Loss 2.6881 Accuracy 0.3414\n",
      "Epoch 9 Loss 2.6581 Accuracy 0.3435\n",
      "Time taken for 1 epoch: 198.2088963985443 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 3.0132 Accuracy 0.3435\n",
      "Epoch 10 Batch 100 Loss 2.7337 Accuracy 0.3458\n",
      "Epoch 10 Batch 200 Loss 2.6622 Accuracy 0.3483\n",
      "Epoch 10 Batch 300 Loss 2.6035 Accuracy 0.3510\n",
      "Epoch 10 Batch 400 Loss 2.5597 Accuracy 0.3537\n",
      "Epoch 10 Batch 500 Loss 2.5022 Accuracy 0.3568\n",
      "Epoch 10 Batch 600 Loss 2.4447 Accuracy 0.3601\n",
      "Epoch 10 Batch 700 Loss 2.3940 Accuracy 0.3634\n",
      "Epoch 10 Batch 800 Loss 2.3488 Accuracy 0.3667\n",
      "Saving checkpoint for epoch 10 at checkpoints/ckpt-16\n",
      "Epoch 10 Loss 2.3245 Accuracy 0.3687\n",
      "Time taken for 1 epoch: 199.35202550888062 secs\n",
      "\n",
      "Epoch 11 Batch 0 Loss 2.7333 Accuracy 0.3687\n",
      "Epoch 11 Batch 100 Loss 2.4438 Accuracy 0.3710\n",
      "Epoch 11 Batch 200 Loss 2.3838 Accuracy 0.3735\n",
      "Epoch 11 Batch 300 Loss 2.3378 Accuracy 0.3760\n",
      "Epoch 11 Batch 400 Loss 2.3012 Accuracy 0.3787\n",
      "Epoch 11 Batch 500 Loss 2.2520 Accuracy 0.3816\n",
      "Epoch 11 Batch 600 Loss 2.2020 Accuracy 0.3846\n",
      "Epoch 11 Batch 700 Loss 2.1560 Accuracy 0.3877\n",
      "Epoch 11 Batch 800 Loss 2.1171 Accuracy 0.3908\n",
      "Epoch 11 Loss 2.0961 Accuracy 0.3926\n",
      "Time taken for 1 epoch: 198.85855627059937 secs\n",
      "\n",
      "Epoch 12 Batch 0 Loss 2.5637 Accuracy 0.3926\n",
      "Epoch 12 Batch 100 Loss 2.2616 Accuracy 0.3947\n",
      "Epoch 12 Batch 200 Loss 2.2056 Accuracy 0.3970\n",
      "Epoch 12 Batch 300 Loss 2.1630 Accuracy 0.3993\n",
      "Epoch 12 Batch 400 Loss 2.1329 Accuracy 0.4017\n",
      "Epoch 12 Batch 500 Loss 2.0862 Accuracy 0.4043\n",
      "Epoch 12 Batch 600 Loss 2.0403 Accuracy 0.4071\n",
      "Epoch 12 Batch 700 Loss 1.9998 Accuracy 0.4099\n",
      "Epoch 12 Batch 800 Loss 1.9658 Accuracy 0.4127\n",
      "Epoch 12 Loss 1.9466 Accuracy 0.4144\n",
      "Time taken for 1 epoch: 198.5082848072052 secs\n",
      "\n",
      "Epoch 13 Batch 0 Loss 2.4901 Accuracy 0.4144\n",
      "Epoch 13 Batch 100 Loss 2.1390 Accuracy 0.4163\n",
      "Epoch 13 Batch 200 Loss 2.0897 Accuracy 0.4184\n",
      "Epoch 13 Batch 300 Loss 2.0457 Accuracy 0.4205\n",
      "Epoch 13 Batch 400 Loss 2.0172 Accuracy 0.4226\n",
      "Epoch 13 Batch 500 Loss 1.9753 Accuracy 0.4250\n",
      "Epoch 13 Batch 600 Loss 1.9321 Accuracy 0.4275\n",
      "Epoch 13 Batch 700 Loss 1.8950 Accuracy 0.4300\n",
      "Epoch 13 Batch 800 Loss 1.8652 Accuracy 0.4326\n",
      "Epoch 13 Loss 1.8482 Accuracy 0.4341\n",
      "Time taken for 1 epoch: 198.47399306297302 secs\n",
      "\n",
      "Epoch 14 Batch 0 Loss 2.4891 Accuracy 0.4341\n",
      "Epoch 14 Batch 100 Loss 2.0428 Accuracy 0.4358\n",
      "Epoch 14 Batch 200 Loss 1.9979 Accuracy 0.4376\n",
      "Epoch 14 Batch 300 Loss 1.9566 Accuracy 0.4396\n",
      "Epoch 14 Batch 400 Loss 1.9315 Accuracy 0.4415\n",
      "Epoch 14 Batch 500 Loss 1.8931 Accuracy 0.4437\n",
      "Epoch 14 Batch 600 Loss 1.8540 Accuracy 0.4459\n",
      "Epoch 14 Batch 700 Loss 1.8208 Accuracy 0.4482\n",
      "Epoch 14 Batch 800 Loss 1.7938 Accuracy 0.4504\n",
      "Epoch 14 Loss 1.7795 Accuracy 0.4518\n",
      "Time taken for 1 epoch: 198.6530122756958 secs\n",
      "\n",
      "Epoch 15 Batch 0 Loss 2.4473 Accuracy 0.4518\n",
      "Epoch 15 Batch 100 Loss 1.9873 Accuracy 0.4533\n",
      "Epoch 15 Batch 200 Loss 1.9420 Accuracy 0.4550\n",
      "Epoch 15 Batch 300 Loss 1.9047 Accuracy 0.4567\n",
      "Epoch 15 Batch 400 Loss 1.8815 Accuracy 0.4585\n",
      "Epoch 15 Batch 500 Loss 1.8418 Accuracy 0.4604\n",
      "Epoch 15 Batch 600 Loss 1.8073 Accuracy 0.4624\n",
      "Epoch 15 Batch 700 Loss 1.7751 Accuracy 0.4645\n",
      "Epoch 15 Batch 800 Loss 1.7494 Accuracy 0.4665\n",
      "Saving checkpoint for epoch 15 at checkpoints/ckpt-17\n",
      "Epoch 15 Loss 1.7363 Accuracy 0.4677\n",
      "Time taken for 1 epoch: 199.2246413230896 secs\n",
      "\n",
      "Epoch 16 Batch 0 Loss 2.2778 Accuracy 0.4677\n",
      "Epoch 16 Batch 100 Loss 1.9490 Accuracy 0.4691\n",
      "Epoch 16 Batch 200 Loss 1.9052 Accuracy 0.4706\n",
      "Epoch 16 Batch 300 Loss 1.8740 Accuracy 0.4721\n",
      "Epoch 16 Batch 400 Loss 1.8523 Accuracy 0.4737\n",
      "Epoch 16 Batch 500 Loss 1.8150 Accuracy 0.4754\n",
      "Epoch 16 Batch 600 Loss 1.7808 Accuracy 0.4773\n",
      "Epoch 16 Batch 700 Loss 1.7494 Accuracy 0.4791\n",
      "Epoch 16 Batch 800 Loss 1.7253 Accuracy 0.4810\n",
      "Epoch 16 Loss 1.7121 Accuracy 0.4821\n",
      "Time taken for 1 epoch: 198.3994915485382 secs\n",
      "\n",
      "Epoch 17 Batch 0 Loss 2.1562 Accuracy 0.4821\n",
      "Epoch 17 Batch 100 Loss 1.9171 Accuracy 0.4833\n",
      "Epoch 17 Batch 200 Loss 1.8763 Accuracy 0.4847\n",
      "Epoch 17 Batch 300 Loss 1.8481 Accuracy 0.4861\n",
      "Epoch 17 Batch 400 Loss 1.8269 Accuracy 0.4875\n",
      "Epoch 17 Batch 500 Loss 1.7931 Accuracy 0.4891\n",
      "Epoch 17 Batch 600 Loss 1.7601 Accuracy 0.4907\n",
      "Epoch 17 Batch 700 Loss 1.7297 Accuracy 0.4924\n",
      "Epoch 17 Batch 800 Loss 1.7056 Accuracy 0.4941\n",
      "Epoch 17 Loss 1.6927 Accuracy 0.4951\n",
      "Time taken for 1 epoch: 198.2011857032776 secs\n",
      "\n",
      "Epoch 18 Batch 0 Loss 2.2682 Accuracy 0.4951\n",
      "Epoch 18 Batch 100 Loss 1.8892 Accuracy 0.4963\n",
      "Epoch 18 Batch 200 Loss 1.8583 Accuracy 0.4975\n",
      "Epoch 18 Batch 300 Loss 1.8332 Accuracy 0.4987\n",
      "Epoch 18 Batch 400 Loss 1.8093 Accuracy 0.5000\n",
      "Epoch 18 Batch 500 Loss 1.7779 Accuracy 0.5015\n",
      "Epoch 18 Batch 600 Loss 1.7465 Accuracy 0.5030\n",
      "Epoch 18 Batch 700 Loss 1.7169 Accuracy 0.5045\n",
      "Epoch 18 Batch 800 Loss 1.6927 Accuracy 0.5061\n",
      "Epoch 18 Loss 1.6804 Accuracy 0.5070\n",
      "Time taken for 1 epoch: 198.4359974861145 secs\n",
      "\n",
      "Epoch 19 Batch 0 Loss 2.2732 Accuracy 0.5070\n",
      "Epoch 19 Batch 100 Loss 1.8760 Accuracy 0.5080\n",
      "Epoch 19 Batch 200 Loss 1.8440 Accuracy 0.5091\n",
      "Epoch 19 Batch 300 Loss 1.8201 Accuracy 0.5103\n",
      "Epoch 19 Batch 400 Loss 1.7968 Accuracy 0.5114\n",
      "Epoch 19 Batch 500 Loss 1.7639 Accuracy 0.5128\n",
      "Epoch 19 Batch 600 Loss 1.7323 Accuracy 0.5142\n",
      "Epoch 19 Batch 700 Loss 1.7042 Accuracy 0.5156\n",
      "Epoch 19 Batch 800 Loss 1.6801 Accuracy 0.5170\n",
      "Epoch 19 Loss 1.6682 Accuracy 0.5178\n",
      "Time taken for 1 epoch: 198.90146708488464 secs\n",
      "\n",
      "Epoch 20 Batch 0 Loss 2.5383 Accuracy 0.5178\n",
      "Epoch 20 Batch 100 Loss 1.8616 Accuracy 0.5188\n",
      "Epoch 20 Batch 200 Loss 1.8281 Accuracy 0.5198\n",
      "Epoch 20 Batch 300 Loss 1.8046 Accuracy 0.5208\n",
      "Epoch 20 Batch 400 Loss 1.7828 Accuracy 0.5219\n",
      "Epoch 20 Batch 500 Loss 1.7479 Accuracy 0.5231\n",
      "Epoch 20 Batch 600 Loss 1.7170 Accuracy 0.5244\n",
      "Epoch 20 Batch 700 Loss 1.6890 Accuracy 0.5257\n",
      "Epoch 20 Batch 800 Loss 1.6652 Accuracy 0.5271\n",
      "Saving checkpoint for epoch 20 at checkpoints/ckpt-18\n",
      "Epoch 20 Loss 1.6536 Accuracy 0.5278\n",
      "Time taken for 1 epoch: 199.1844458580017 secs\n",
      "\n",
      "Epoch 21 Batch 0 Loss 2.2566 Accuracy 0.5278\n",
      "Epoch 21 Batch 100 Loss 1.8489 Accuracy 0.5287\n",
      "Epoch 21 Batch 200 Loss 1.8098 Accuracy 0.5296\n",
      "Epoch 21 Batch 300 Loss 1.7808 Accuracy 0.5306\n",
      "Epoch 21 Batch 400 Loss 1.7630 Accuracy 0.5316\n",
      "Epoch 21 Batch 500 Loss 1.7314 Accuracy 0.5327\n",
      "Epoch 21 Batch 600 Loss 1.7008 Accuracy 0.5339\n",
      "Epoch 21 Batch 700 Loss 1.6730 Accuracy 0.5351\n",
      "Epoch 21 Batch 800 Loss 1.6508 Accuracy 0.5363\n",
      "Epoch 21 Loss 1.6381 Accuracy 0.5370\n",
      "Time taken for 1 epoch: 198.44646382331848 secs\n",
      "\n",
      "Epoch 22 Batch 0 Loss 2.0817 Accuracy 0.5370\n",
      "Epoch 22 Batch 100 Loss 1.8386 Accuracy 0.5378\n",
      "Epoch 22 Batch 200 Loss 1.7987 Accuracy 0.5387\n",
      "Epoch 22 Batch 300 Loss 1.7692 Accuracy 0.5395\n",
      "Epoch 22 Batch 400 Loss 1.7500 Accuracy 0.5405\n",
      "Epoch 22 Batch 500 Loss 1.7171 Accuracy 0.5415\n",
      "Epoch 22 Batch 600 Loss 1.6838 Accuracy 0.5426\n",
      "Epoch 22 Batch 700 Loss 1.6568 Accuracy 0.5438\n",
      "Epoch 22 Batch 800 Loss 1.6328 Accuracy 0.5449\n",
      "Epoch 22 Loss 1.6213 Accuracy 0.5456\n",
      "Time taken for 1 epoch: 198.4818639755249 secs\n",
      "\n",
      "Epoch 23 Batch 0 Loss 2.1040 Accuracy 0.5456\n",
      "Epoch 23 Batch 100 Loss 1.8183 Accuracy 0.5463\n",
      "Epoch 23 Batch 200 Loss 1.7828 Accuracy 0.5471\n",
      "Epoch 23 Batch 300 Loss 1.7533 Accuracy 0.5479\n",
      "Epoch 23 Batch 400 Loss 1.7312 Accuracy 0.5487\n",
      "Epoch 23 Batch 500 Loss 1.7017 Accuracy 0.5497\n",
      "Epoch 23 Batch 600 Loss 1.6684 Accuracy 0.5507\n",
      "Epoch 23 Batch 700 Loss 1.6413 Accuracy 0.5518\n",
      "Epoch 23 Batch 800 Loss 1.6169 Accuracy 0.5528\n",
      "Epoch 23 Loss 1.6057 Accuracy 0.5534\n",
      "Time taken for 1 epoch: 198.66815853118896 secs\n",
      "\n",
      "Epoch 24 Batch 0 Loss 2.1812 Accuracy 0.5535\n",
      "Epoch 24 Batch 100 Loss 1.8001 Accuracy 0.5541\n",
      "Epoch 24 Batch 200 Loss 1.7584 Accuracy 0.5548\n",
      "Epoch 24 Batch 300 Loss 1.7343 Accuracy 0.5556\n",
      "Epoch 24 Batch 400 Loss 1.7143 Accuracy 0.5564\n",
      "Epoch 24 Batch 500 Loss 1.6835 Accuracy 0.5573\n",
      "Epoch 24 Batch 600 Loss 1.6512 Accuracy 0.5583\n",
      "Epoch 24 Batch 700 Loss 1.6238 Accuracy 0.5592\n",
      "Epoch 24 Batch 800 Loss 1.6004 Accuracy 0.5602\n",
      "Epoch 24 Loss 1.5895 Accuracy 0.5608\n",
      "Time taken for 1 epoch: 198.81537055969238 secs\n",
      "\n",
      "Epoch 25 Batch 0 Loss 2.0749 Accuracy 0.5608\n",
      "Epoch 25 Batch 100 Loss 1.7861 Accuracy 0.5614\n",
      "Epoch 25 Batch 200 Loss 1.7505 Accuracy 0.5621\n",
      "Epoch 25 Batch 300 Loss 1.7222 Accuracy 0.5628\n",
      "Epoch 25 Batch 400 Loss 1.7027 Accuracy 0.5635\n",
      "Epoch 25 Batch 500 Loss 1.6729 Accuracy 0.5644\n",
      "Epoch 25 Batch 600 Loss 1.6412 Accuracy 0.5653\n",
      "Epoch 25 Batch 700 Loss 1.6141 Accuracy 0.5662\n",
      "Epoch 25 Batch 800 Loss 1.5918 Accuracy 0.5671\n",
      "Saving checkpoint for epoch 25 at checkpoints/ckpt-19\n",
      "Epoch 25 Loss 1.5808 Accuracy 0.5676\n",
      "Time taken for 1 epoch: 199.64822125434875 secs\n",
      "\n",
      "Epoch 26 Batch 0 Loss 2.2170 Accuracy 0.5676\n",
      "Epoch 26 Batch 100 Loss 1.7788 Accuracy 0.5682\n",
      "Epoch 26 Batch 200 Loss 1.7404 Accuracy 0.5688\n",
      "Epoch 26 Batch 300 Loss 1.7133 Accuracy 0.5694\n",
      "Epoch 26 Batch 400 Loss 1.6946 Accuracy 0.5701\n",
      "Epoch 26 Batch 500 Loss 1.6655 Accuracy 0.5709\n",
      "Epoch 26 Batch 600 Loss 1.6344 Accuracy 0.5718\n",
      "Epoch 26 Batch 700 Loss 1.6062 Accuracy 0.5726\n",
      "Epoch 26 Batch 800 Loss 1.5840 Accuracy 0.5735\n",
      "Epoch 26 Loss 1.5724 Accuracy 0.5740\n",
      "Time taken for 1 epoch: 198.74893045425415 secs\n",
      "\n",
      "Epoch 27 Batch 0 Loss 2.0339 Accuracy 0.5740\n",
      "Epoch 27 Batch 100 Loss 1.7581 Accuracy 0.5745\n",
      "Epoch 27 Batch 200 Loss 1.7319 Accuracy 0.5751\n",
      "Epoch 27 Batch 300 Loss 1.7061 Accuracy 0.5757\n",
      "Epoch 27 Batch 400 Loss 1.6861 Accuracy 0.5763\n",
      "Epoch 27 Batch 500 Loss 1.6558 Accuracy 0.5771\n",
      "Epoch 27 Batch 600 Loss 1.6229 Accuracy 0.5779\n",
      "Epoch 27 Batch 700 Loss 1.5950 Accuracy 0.5787\n",
      "Epoch 27 Batch 800 Loss 1.5734 Accuracy 0.5795\n",
      "Epoch 27 Loss 1.5622 Accuracy 0.5800\n",
      "Time taken for 1 epoch: 198.3034679889679 secs\n",
      "\n",
      "Epoch 28 Batch 0 Loss 2.1115 Accuracy 0.5800\n",
      "Epoch 28 Batch 100 Loss 1.7585 Accuracy 0.5805\n",
      "Epoch 28 Batch 200 Loss 1.7298 Accuracy 0.5810\n",
      "Epoch 28 Batch 300 Loss 1.7011 Accuracy 0.5816\n",
      "Epoch 28 Batch 400 Loss 1.6805 Accuracy 0.5822\n",
      "Epoch 28 Batch 500 Loss 1.6508 Accuracy 0.5829\n",
      "Epoch 28 Batch 600 Loss 1.6202 Accuracy 0.5836\n",
      "Epoch 28 Batch 700 Loss 1.5937 Accuracy 0.5844\n",
      "Epoch 28 Batch 800 Loss 1.5705 Accuracy 0.5851\n",
      "Epoch 28 Loss 1.5602 Accuracy 0.5856\n",
      "Time taken for 1 epoch: 198.2496898174286 secs\n",
      "\n",
      "Epoch 29 Batch 0 Loss 1.9360 Accuracy 0.5856\n",
      "Epoch 29 Batch 100 Loss 1.7473 Accuracy 0.5861\n",
      "Epoch 29 Batch 200 Loss 1.7214 Accuracy 0.5866\n",
      "Epoch 29 Batch 300 Loss 1.6915 Accuracy 0.5871\n",
      "Epoch 29 Batch 400 Loss 1.6705 Accuracy 0.5877\n",
      "Epoch 29 Batch 500 Loss 1.6399 Accuracy 0.5883\n",
      "Epoch 29 Batch 600 Loss 1.6100 Accuracy 0.5890\n",
      "Epoch 29 Batch 700 Loss 1.5824 Accuracy 0.5898\n",
      "Epoch 29 Batch 800 Loss 1.5607 Accuracy 0.5905\n",
      "Epoch 29 Loss 1.5506 Accuracy 0.5909\n",
      "Time taken for 1 epoch: 198.43819570541382 secs\n",
      "\n",
      "Epoch 30 Batch 0 Loss 2.1197 Accuracy 0.5909\n",
      "Epoch 30 Batch 100 Loss 1.7419 Accuracy 0.5913\n",
      "Epoch 30 Batch 200 Loss 1.7105 Accuracy 0.5918\n",
      "Epoch 30 Batch 300 Loss 1.6823 Accuracy 0.5923\n",
      "Epoch 30 Batch 400 Loss 1.6631 Accuracy 0.5929\n",
      "Epoch 30 Batch 500 Loss 1.6336 Accuracy 0.5935\n",
      "Epoch 30 Batch 600 Loss 1.6017 Accuracy 0.5942\n",
      "Epoch 30 Batch 700 Loss 1.5765 Accuracy 0.5948\n",
      "Epoch 30 Batch 800 Loss 1.5542 Accuracy 0.5955\n",
      "Saving checkpoint for epoch 30 at checkpoints/ckpt-20\n",
      "Epoch 30 Loss 1.5442 Accuracy 0.5959\n",
      "Time taken for 1 epoch: 199.42691612243652 secs\n",
      "\n",
      "Epoch 31 Batch 0 Loss 1.7770 Accuracy 0.5959\n",
      "Epoch 31 Batch 100 Loss 1.7418 Accuracy 0.5963\n",
      "Epoch 31 Batch 200 Loss 1.7008 Accuracy 0.5968\n",
      "Epoch 31 Batch 300 Loss 1.6754 Accuracy 0.5972\n",
      "Epoch 31 Batch 400 Loss 1.6578 Accuracy 0.5977\n",
      "Epoch 31 Batch 500 Loss 1.6261 Accuracy 0.5983\n",
      "Epoch 31 Batch 600 Loss 1.5951 Accuracy 0.5990\n",
      "Epoch 31 Batch 700 Loss 1.5685 Accuracy 0.5996\n",
      "Epoch 31 Batch 800 Loss 1.5479 Accuracy 0.6003\n",
      "Epoch 31 Loss 1.5367 Accuracy 0.6007\n",
      "Time taken for 1 epoch: 198.04773378372192 secs\n",
      "\n",
      "Epoch 32 Batch 0 Loss 2.0582 Accuracy 0.6007\n",
      "Epoch 32 Batch 100 Loss 1.7335 Accuracy 0.6010\n",
      "Epoch 32 Batch 200 Loss 1.6946 Accuracy 0.6015\n",
      "Epoch 32 Batch 300 Loss 1.6690 Accuracy 0.6019\n",
      "Epoch 32 Batch 400 Loss 1.6491 Accuracy 0.6024\n",
      "Epoch 32 Batch 500 Loss 1.6198 Accuracy 0.6029\n",
      "Epoch 32 Batch 600 Loss 1.5896 Accuracy 0.6035\n",
      "Epoch 32 Batch 700 Loss 1.5642 Accuracy 0.6042\n",
      "Epoch 32 Batch 800 Loss 1.5431 Accuracy 0.6048\n",
      "Epoch 32 Loss 1.5325 Accuracy 0.6051\n",
      "Time taken for 1 epoch: 198.29104042053223 secs\n",
      "\n",
      "Epoch 33 Batch 0 Loss 2.1265 Accuracy 0.6051\n",
      "Epoch 33 Batch 100 Loss 1.7214 Accuracy 0.6055\n",
      "Epoch 33 Batch 200 Loss 1.6902 Accuracy 0.6059\n",
      "Epoch 33 Batch 300 Loss 1.6606 Accuracy 0.6063\n",
      "Epoch 33 Batch 400 Loss 1.6442 Accuracy 0.6068\n",
      "Epoch 33 Batch 500 Loss 1.6145 Accuracy 0.6073\n",
      "Epoch 33 Batch 600 Loss 1.5831 Accuracy 0.6079\n",
      "Epoch 33 Batch 700 Loss 1.5562 Accuracy 0.6085\n",
      "Epoch 33 Batch 800 Loss 1.5370 Accuracy 0.6090\n",
      "Epoch 33 Loss 1.5259 Accuracy 0.6094\n",
      "Time taken for 1 epoch: 198.3161985874176 secs\n",
      "\n",
      "Epoch 34 Batch 0 Loss 1.9200 Accuracy 0.6094\n",
      "Epoch 34 Batch 100 Loss 1.7088 Accuracy 0.6097\n",
      "Epoch 34 Batch 200 Loss 1.6828 Accuracy 0.6101\n",
      "Epoch 34 Batch 300 Loss 1.6536 Accuracy 0.6105\n",
      "Epoch 34 Batch 400 Loss 1.6369 Accuracy 0.6109\n",
      "Epoch 34 Batch 500 Loss 1.6077 Accuracy 0.6114\n",
      "Epoch 34 Batch 600 Loss 1.5768 Accuracy 0.6120\n",
      "Epoch 34 Batch 700 Loss 1.5499 Accuracy 0.6125\n",
      "Epoch 34 Batch 800 Loss 1.5288 Accuracy 0.6131\n",
      "Epoch 34 Loss 1.5196 Accuracy 0.6134\n",
      "Time taken for 1 epoch: 197.77343034744263 secs\n",
      "\n",
      "Epoch 35 Batch 0 Loss 1.8167 Accuracy 0.6134\n",
      "Epoch 35 Batch 100 Loss 1.7141 Accuracy 0.6138\n",
      "Epoch 35 Batch 200 Loss 1.6786 Accuracy 0.6141\n",
      "Epoch 35 Batch 300 Loss 1.6498 Accuracy 0.6145\n",
      "Epoch 35 Batch 400 Loss 1.6315 Accuracy 0.6149\n",
      "Epoch 35 Batch 500 Loss 1.6022 Accuracy 0.6154\n",
      "Epoch 35 Batch 600 Loss 1.5712 Accuracy 0.6159\n",
      "Epoch 35 Batch 700 Loss 1.5460 Accuracy 0.6165\n",
      "Epoch 35 Batch 800 Loss 1.5254 Accuracy 0.6170\n",
      "Saving checkpoint for epoch 35 at checkpoints/ckpt-21\n",
      "Epoch 35 Loss 1.5157 Accuracy 0.6173\n",
      "Time taken for 1 epoch: 198.92308592796326 secs\n",
      "\n",
      "Epoch 36 Batch 0 Loss 1.7400 Accuracy 0.6173\n",
      "Epoch 36 Batch 100 Loss 1.7022 Accuracy 0.6176\n",
      "Epoch 36 Batch 200 Loss 1.6710 Accuracy 0.6179\n",
      "Epoch 36 Batch 300 Loss 1.6434 Accuracy 0.6183\n",
      "Epoch 36 Batch 400 Loss 1.6249 Accuracy 0.6187\n",
      "Epoch 36 Batch 500 Loss 1.5963 Accuracy 0.6192\n",
      "Epoch 36 Batch 600 Loss 1.5640 Accuracy 0.6197\n",
      "Epoch 36 Batch 700 Loss 1.5387 Accuracy 0.6202\n",
      "Epoch 36 Batch 800 Loss 1.5185 Accuracy 0.6207\n",
      "Epoch 36 Loss 1.5082 Accuracy 0.6210\n",
      "Time taken for 1 epoch: 198.19265222549438 secs\n",
      "\n",
      "Epoch 37 Batch 0 Loss 2.1929 Accuracy 0.6210\n",
      "Epoch 37 Batch 100 Loss 1.7138 Accuracy 0.6213\n",
      "Epoch 37 Batch 200 Loss 1.6714 Accuracy 0.6216\n",
      "Epoch 37 Batch 300 Loss 1.6391 Accuracy 0.6220\n",
      "Epoch 37 Batch 400 Loss 1.6199 Accuracy 0.6223\n",
      "Epoch 37 Batch 500 Loss 1.5917 Accuracy 0.6228\n",
      "Epoch 37 Batch 600 Loss 1.5594 Accuracy 0.6233\n",
      "Epoch 37 Batch 700 Loss 1.5338 Accuracy 0.6237\n",
      "Epoch 37 Batch 800 Loss 1.5137 Accuracy 0.6242\n",
      "Epoch 37 Loss 1.5034 Accuracy 0.6245\n",
      "Time taken for 1 epoch: 197.85219192504883 secs\n",
      "\n",
      "Epoch 38 Batch 0 Loss 2.1303 Accuracy 0.6245\n",
      "Epoch 38 Batch 100 Loss 1.7043 Accuracy 0.6248\n",
      "Epoch 38 Batch 200 Loss 1.6644 Accuracy 0.6251\n",
      "Epoch 38 Batch 300 Loss 1.6342 Accuracy 0.6254\n",
      "Epoch 38 Batch 400 Loss 1.6144 Accuracy 0.6258\n",
      "Epoch 38 Batch 500 Loss 1.5848 Accuracy 0.6262\n",
      "Epoch 38 Batch 600 Loss 1.5530 Accuracy 0.6267\n",
      "Epoch 38 Batch 700 Loss 1.5275 Accuracy 0.6271\n",
      "Epoch 38 Batch 800 Loss 1.5060 Accuracy 0.6276\n",
      "Epoch 38 Loss 1.4966 Accuracy 0.6279\n",
      "Time taken for 1 epoch: 197.84684443473816 secs\n",
      "\n",
      "Epoch 39 Batch 0 Loss 2.0917 Accuracy 0.6279\n",
      "Epoch 39 Batch 100 Loss 1.6793 Accuracy 0.6282\n",
      "Epoch 39 Batch 200 Loss 1.6486 Accuracy 0.6284\n",
      "Epoch 39 Batch 300 Loss 1.6228 Accuracy 0.6288\n",
      "Epoch 39 Batch 400 Loss 1.6029 Accuracy 0.6291\n",
      "Epoch 39 Batch 500 Loss 1.5737 Accuracy 0.6295\n",
      "Epoch 39 Batch 600 Loss 1.5443 Accuracy 0.6300\n",
      "Epoch 39 Batch 700 Loss 1.5174 Accuracy 0.6304\n",
      "Epoch 39 Batch 800 Loss 1.4976 Accuracy 0.6309\n",
      "Epoch 39 Loss 1.4886 Accuracy 0.6311\n",
      "Time taken for 1 epoch: 197.93238759040833 secs\n",
      "\n",
      "Epoch 40 Batch 0 Loss 1.7491 Accuracy 0.6311\n",
      "Epoch 40 Batch 100 Loss 1.6719 Accuracy 0.6314\n",
      "Epoch 40 Batch 200 Loss 1.6396 Accuracy 0.6317\n",
      "Epoch 40 Batch 300 Loss 1.6137 Accuracy 0.6320\n",
      "Epoch 40 Batch 400 Loss 1.5955 Accuracy 0.6323\n",
      "Epoch 40 Batch 500 Loss 1.5699 Accuracy 0.6327\n",
      "Epoch 40 Batch 600 Loss 1.5371 Accuracy 0.6331\n",
      "Epoch 40 Batch 700 Loss 1.5112 Accuracy 0.6336\n",
      "Epoch 40 Batch 800 Loss 1.4924 Accuracy 0.6340\n",
      "Saving checkpoint for epoch 40 at checkpoints/ckpt-22\n",
      "Epoch 40 Loss 1.4828 Accuracy 0.6342\n",
      "Time taken for 1 epoch: 198.56715750694275 secs\n",
      "\n",
      "Epoch 41 Batch 0 Loss 1.9297 Accuracy 0.6342\n",
      "Epoch 41 Batch 100 Loss 1.6734 Accuracy 0.6345\n",
      "Epoch 41 Batch 200 Loss 1.6358 Accuracy 0.6347\n",
      "Epoch 41 Batch 300 Loss 1.6091 Accuracy 0.6350\n",
      "Epoch 41 Batch 400 Loss 1.5902 Accuracy 0.6354\n",
      "Epoch 41 Batch 500 Loss 1.5618 Accuracy 0.6357\n",
      "Epoch 41 Batch 600 Loss 1.5335 Accuracy 0.6361\n",
      "Epoch 41 Batch 700 Loss 1.5066 Accuracy 0.6366\n",
      "Epoch 41 Batch 800 Loss 1.4867 Accuracy 0.6370\n",
      "Epoch 41 Loss 1.4769 Accuracy 0.6372\n",
      "Time taken for 1 epoch: 198.0629026889801 secs\n",
      "\n",
      "Epoch 42 Batch 0 Loss 1.8610 Accuracy 0.6372\n",
      "Epoch 42 Batch 100 Loss 1.6638 Accuracy 0.6375\n",
      "Epoch 42 Batch 200 Loss 1.6240 Accuracy 0.6377\n",
      "Epoch 42 Batch 300 Loss 1.5989 Accuracy 0.6380\n",
      "Epoch 42 Batch 400 Loss 1.5791 Accuracy 0.6383\n",
      "Epoch 42 Batch 500 Loss 1.5546 Accuracy 0.6387\n",
      "Epoch 42 Batch 600 Loss 1.5250 Accuracy 0.6391\n",
      "Epoch 42 Batch 700 Loss 1.5002 Accuracy 0.6395\n",
      "Epoch 42 Batch 800 Loss 1.4809 Accuracy 0.6399\n",
      "Epoch 42 Loss 1.4706 Accuracy 0.6401\n",
      "Time taken for 1 epoch: 198.03233528137207 secs\n",
      "\n",
      "Epoch 43 Batch 0 Loss 2.1805 Accuracy 0.6401\n",
      "Epoch 43 Batch 100 Loss 1.6595 Accuracy 0.6404\n",
      "Epoch 43 Batch 200 Loss 1.6243 Accuracy 0.6406\n",
      "Epoch 43 Batch 300 Loss 1.5955 Accuracy 0.6409\n",
      "Epoch 43 Batch 400 Loss 1.5767 Accuracy 0.6412\n",
      "Epoch 43 Batch 500 Loss 1.5504 Accuracy 0.6415\n",
      "Epoch 43 Batch 600 Loss 1.5203 Accuracy 0.6419\n",
      "Epoch 43 Batch 700 Loss 1.4955 Accuracy 0.6423\n",
      "Epoch 43 Batch 800 Loss 1.4764 Accuracy 0.6427\n",
      "Epoch 43 Loss 1.4661 Accuracy 0.6429\n",
      "Time taken for 1 epoch: 198.1517562866211 secs\n",
      "\n",
      "Epoch 44 Batch 0 Loss 1.9444 Accuracy 0.6429\n",
      "Epoch 44 Batch 100 Loss 1.6557 Accuracy 0.6431\n",
      "Epoch 44 Batch 200 Loss 1.6214 Accuracy 0.6433\n",
      "Epoch 44 Batch 300 Loss 1.5920 Accuracy 0.6436\n",
      "Epoch 44 Batch 400 Loss 1.5716 Accuracy 0.6439\n",
      "Epoch 44 Batch 500 Loss 1.5442 Accuracy 0.6442\n",
      "Epoch 44 Batch 600 Loss 1.5141 Accuracy 0.6446\n",
      "Epoch 44 Batch 700 Loss 1.4894 Accuracy 0.6450\n",
      "Epoch 44 Batch 800 Loss 1.4702 Accuracy 0.6454\n",
      "Epoch 44 Loss 1.4610 Accuracy 0.6456\n",
      "Time taken for 1 epoch: 198.21566891670227 secs\n",
      "\n",
      "Epoch 45 Batch 0 Loss 2.0294 Accuracy 0.6456\n",
      "Epoch 45 Batch 100 Loss 1.6483 Accuracy 0.6458\n",
      "Epoch 45 Batch 200 Loss 1.6120 Accuracy 0.6460\n",
      "Epoch 45 Batch 300 Loss 1.5819 Accuracy 0.6463\n",
      "Epoch 45 Batch 400 Loss 1.5602 Accuracy 0.6465\n",
      "Epoch 45 Batch 500 Loss 1.5326 Accuracy 0.6469\n",
      "Epoch 45 Batch 600 Loss 1.5047 Accuracy 0.6472\n",
      "Epoch 45 Batch 700 Loss 1.4810 Accuracy 0.6476\n",
      "Epoch 45 Batch 800 Loss 1.4621 Accuracy 0.6480\n",
      "Saving checkpoint for epoch 45 at checkpoints/ckpt-23\n",
      "Epoch 45 Loss 1.4531 Accuracy 0.6482\n",
      "Time taken for 1 epoch: 198.77923250198364 secs\n",
      "\n",
      "Epoch 46 Batch 0 Loss 1.8556 Accuracy 0.6482\n",
      "Epoch 46 Batch 100 Loss 1.6396 Accuracy 0.6484\n",
      "Epoch 46 Batch 200 Loss 1.6104 Accuracy 0.6486\n",
      "Epoch 46 Batch 300 Loss 1.5807 Accuracy 0.6488\n",
      "Epoch 46 Batch 400 Loss 1.5599 Accuracy 0.6491\n",
      "Epoch 46 Batch 500 Loss 1.5319 Accuracy 0.6494\n",
      "Epoch 46 Batch 600 Loss 1.5039 Accuracy 0.6498\n",
      "Epoch 46 Batch 700 Loss 1.4782 Accuracy 0.6501\n",
      "Epoch 46 Batch 800 Loss 1.4585 Accuracy 0.6505\n",
      "Epoch 46 Loss 1.4496 Accuracy 0.6507\n",
      "Time taken for 1 epoch: 198.71602535247803 secs\n",
      "\n",
      "Epoch 47 Batch 0 Loss 1.9284 Accuracy 0.6507\n",
      "Epoch 47 Batch 100 Loss 1.6208 Accuracy 0.6509\n",
      "Epoch 47 Batch 200 Loss 1.5928 Accuracy 0.6511\n",
      "Epoch 47 Batch 300 Loss 1.5693 Accuracy 0.6513\n",
      "Epoch 47 Batch 400 Loss 1.5493 Accuracy 0.6516\n",
      "Epoch 47 Batch 500 Loss 1.5223 Accuracy 0.6519\n",
      "Epoch 47 Batch 600 Loss 1.4937 Accuracy 0.6522\n",
      "Epoch 47 Batch 700 Loss 1.4696 Accuracy 0.6526\n",
      "Epoch 47 Batch 800 Loss 1.4510 Accuracy 0.6529\n",
      "Epoch 47 Loss 1.4417 Accuracy 0.6531\n",
      "Time taken for 1 epoch: 198.93197345733643 secs\n",
      "\n",
      "Epoch 48 Batch 0 Loss 1.7703 Accuracy 0.6531\n",
      "Epoch 48 Batch 100 Loss 1.6274 Accuracy 0.6533\n",
      "Epoch 48 Batch 200 Loss 1.5985 Accuracy 0.6535\n",
      "Epoch 48 Batch 300 Loss 1.5691 Accuracy 0.6537\n",
      "Epoch 48 Batch 400 Loss 1.5499 Accuracy 0.6540\n",
      "Epoch 48 Batch 500 Loss 1.5216 Accuracy 0.6543\n",
      "Epoch 48 Batch 600 Loss 1.4939 Accuracy 0.6546\n",
      "Epoch 48 Batch 700 Loss 1.4687 Accuracy 0.6549\n",
      "Epoch 48 Batch 800 Loss 1.4480 Accuracy 0.6553\n",
      "Epoch 48 Loss 1.4391 Accuracy 0.6555\n",
      "Time taken for 1 epoch: 199.15874552726746 secs\n",
      "\n",
      "Epoch 49 Batch 0 Loss 1.8617 Accuracy 0.6555\n",
      "Epoch 49 Batch 100 Loss 1.6215 Accuracy 0.6556\n",
      "Epoch 49 Batch 200 Loss 1.5859 Accuracy 0.6558\n",
      "Epoch 49 Batch 300 Loss 1.5610 Accuracy 0.6560\n",
      "Epoch 49 Batch 400 Loss 1.5416 Accuracy 0.6563\n",
      "Epoch 49 Batch 500 Loss 1.5134 Accuracy 0.6566\n",
      "Epoch 49 Batch 600 Loss 1.4855 Accuracy 0.6569\n",
      "Epoch 49 Batch 700 Loss 1.4600 Accuracy 0.6572\n",
      "Epoch 49 Batch 800 Loss 1.4410 Accuracy 0.6575\n",
      "Epoch 49 Loss 1.4316 Accuracy 0.6577\n",
      "Time taken for 1 epoch: 198.92071175575256 secs\n",
      "\n",
      "Epoch 50 Batch 0 Loss 1.9528 Accuracy 0.6577\n",
      "Epoch 50 Batch 100 Loss 1.6141 Accuracy 0.6579\n",
      "Epoch 50 Batch 200 Loss 1.5871 Accuracy 0.6581\n",
      "Epoch 50 Batch 300 Loss 1.5555 Accuracy 0.6583\n",
      "Epoch 50 Batch 400 Loss 1.5369 Accuracy 0.6585\n",
      "Epoch 50 Batch 500 Loss 1.5105 Accuracy 0.6588\n",
      "Epoch 50 Batch 600 Loss 1.4817 Accuracy 0.6591\n",
      "Epoch 50 Batch 700 Loss 1.4571 Accuracy 0.6594\n",
      "Epoch 50 Batch 800 Loss 1.4367 Accuracy 0.6597\n",
      "Saving checkpoint for epoch 50 at checkpoints/ckpt-24\n",
      "Epoch 50 Loss 1.4279 Accuracy 0.6599\n",
      "Time taken for 1 epoch: 199.3192834854126 secs\n",
      "\n",
      "Epoch 51 Batch 0 Loss 1.8947 Accuracy 0.6599\n",
      "Epoch 51 Batch 100 Loss 1.6041 Accuracy 0.6601\n",
      "Epoch 51 Batch 200 Loss 1.5721 Accuracy 0.6603\n",
      "Epoch 51 Batch 300 Loss 1.5445 Accuracy 0.6605\n",
      "Epoch 51 Batch 400 Loss 1.5291 Accuracy 0.6607\n",
      "Epoch 51 Batch 500 Loss 1.5029 Accuracy 0.6610\n",
      "Epoch 51 Batch 600 Loss 1.4758 Accuracy 0.6613\n",
      "Epoch 51 Batch 700 Loss 1.4497 Accuracy 0.6616\n",
      "Epoch 51 Batch 800 Loss 1.4299 Accuracy 0.6619\n",
      "Epoch 51 Loss 1.4210 Accuracy 0.6621\n",
      "Time taken for 1 epoch: 198.95630264282227 secs\n",
      "\n",
      "Epoch 52 Batch 0 Loss 1.7642 Accuracy 0.6621\n",
      "Epoch 52 Batch 100 Loss 1.6103 Accuracy 0.6622\n",
      "Epoch 52 Batch 200 Loss 1.5724 Accuracy 0.6624\n",
      "Epoch 52 Batch 300 Loss 1.5441 Accuracy 0.6626\n",
      "Epoch 52 Batch 400 Loss 1.5253 Accuracy 0.6628\n",
      "Epoch 52 Batch 500 Loss 1.4992 Accuracy 0.6631\n",
      "Epoch 52 Batch 600 Loss 1.4694 Accuracy 0.6634\n",
      "Epoch 52 Batch 700 Loss 1.4459 Accuracy 0.6637\n",
      "Epoch 52 Batch 800 Loss 1.4268 Accuracy 0.6640\n",
      "Epoch 52 Loss 1.4175 Accuracy 0.6641\n",
      "Time taken for 1 epoch: 198.95192646980286 secs\n",
      "\n",
      "Epoch 53 Batch 0 Loss 1.8266 Accuracy 0.6641\n",
      "Epoch 53 Batch 100 Loss 1.5965 Accuracy 0.6643\n",
      "Epoch 53 Batch 200 Loss 1.5609 Accuracy 0.6645\n",
      "Epoch 53 Batch 300 Loss 1.5337 Accuracy 0.6647\n",
      "Epoch 53 Batch 400 Loss 1.5181 Accuracy 0.6649\n",
      "Epoch 53 Batch 500 Loss 1.4902 Accuracy 0.6651\n",
      "Epoch 53 Batch 600 Loss 1.4621 Accuracy 0.6654\n",
      "Epoch 53 Batch 700 Loss 1.4378 Accuracy 0.6657\n",
      "Epoch 53 Batch 800 Loss 1.4189 Accuracy 0.6660\n",
      "Epoch 53 Loss 1.4101 Accuracy 0.6662\n",
      "Time taken for 1 epoch: 198.62052655220032 secs\n",
      "\n",
      "Epoch 54 Batch 0 Loss 1.9676 Accuracy 0.6662\n",
      "Epoch 54 Batch 100 Loss 1.5948 Accuracy 0.6663\n",
      "Epoch 54 Batch 200 Loss 1.5598 Accuracy 0.6665\n",
      "Epoch 54 Batch 300 Loss 1.5314 Accuracy 0.6667\n",
      "Epoch 54 Batch 400 Loss 1.5122 Accuracy 0.6669\n",
      "Epoch 54 Batch 500 Loss 1.4849 Accuracy 0.6671\n",
      "Epoch 54 Batch 600 Loss 1.4564 Accuracy 0.6674\n",
      "Epoch 54 Batch 700 Loss 1.4316 Accuracy 0.6677\n",
      "Epoch 54 Batch 800 Loss 1.4132 Accuracy 0.6680\n",
      "Epoch 54 Loss 1.4042 Accuracy 0.6681\n",
      "Time taken for 1 epoch: 198.23452854156494 secs\n",
      "\n",
      "Epoch 55 Batch 0 Loss 1.9403 Accuracy 0.6681\n",
      "Epoch 55 Batch 100 Loss 1.5774 Accuracy 0.6683\n",
      "Epoch 55 Batch 200 Loss 1.5470 Accuracy 0.6685\n",
      "Epoch 55 Batch 300 Loss 1.5212 Accuracy 0.6686\n",
      "Epoch 55 Batch 400 Loss 1.5044 Accuracy 0.6688\n",
      "Epoch 55 Batch 500 Loss 1.4798 Accuracy 0.6691\n",
      "Epoch 55 Batch 600 Loss 1.4522 Accuracy 0.6693\n",
      "Epoch 55 Batch 700 Loss 1.4284 Accuracy 0.6696\n",
      "Epoch 55 Batch 800 Loss 1.4092 Accuracy 0.6699\n",
      "Saving checkpoint for epoch 55 at checkpoints/ckpt-25\n",
      "Epoch 55 Loss 1.4001 Accuracy 0.6701\n",
      "Time taken for 1 epoch: 199.13613367080688 secs\n",
      "\n",
      "Epoch 56 Batch 0 Loss 1.8577 Accuracy 0.6701\n",
      "Epoch 56 Batch 100 Loss 1.5739 Accuracy 0.6702\n",
      "Epoch 56 Batch 200 Loss 1.5462 Accuracy 0.6704\n",
      "Epoch 56 Batch 300 Loss 1.5196 Accuracy 0.6705\n",
      "Epoch 56 Batch 400 Loss 1.4994 Accuracy 0.6707\n",
      "Epoch 56 Batch 500 Loss 1.4738 Accuracy 0.6710\n",
      "Epoch 56 Batch 600 Loss 1.4457 Accuracy 0.6712\n",
      "Epoch 56 Batch 700 Loss 1.4222 Accuracy 0.6715\n",
      "Epoch 56 Batch 800 Loss 1.4038 Accuracy 0.6718\n",
      "Epoch 56 Loss 1.3945 Accuracy 0.6719\n",
      "Time taken for 1 epoch: 198.74303078651428 secs\n",
      "\n",
      "Epoch 57 Batch 0 Loss 1.6275 Accuracy 0.6719\n",
      "Epoch 57 Batch 100 Loss 1.5740 Accuracy 0.6721\n",
      "Epoch 57 Batch 200 Loss 1.5394 Accuracy 0.6722\n",
      "Epoch 57 Batch 300 Loss 1.5104 Accuracy 0.6724\n",
      "Epoch 57 Batch 400 Loss 1.4932 Accuracy 0.6726\n",
      "Epoch 57 Batch 500 Loss 1.4684 Accuracy 0.6728\n",
      "Epoch 57 Batch 600 Loss 1.4406 Accuracy 0.6731\n",
      "Epoch 57 Batch 700 Loss 1.4154 Accuracy 0.6733\n",
      "Epoch 57 Batch 800 Loss 1.3960 Accuracy 0.6736\n",
      "Epoch 57 Loss 1.3881 Accuracy 0.6737\n",
      "Time taken for 1 epoch: 198.66526794433594 secs\n",
      "\n",
      "Epoch 58 Batch 0 Loss 1.6075 Accuracy 0.6737\n",
      "Epoch 58 Batch 100 Loss 1.5734 Accuracy 0.6739\n",
      "Epoch 58 Batch 200 Loss 1.5340 Accuracy 0.6740\n",
      "Epoch 58 Batch 300 Loss 1.5073 Accuracy 0.6742\n",
      "Epoch 58 Batch 400 Loss 1.4882 Accuracy 0.6744\n",
      "Epoch 58 Batch 500 Loss 1.4630 Accuracy 0.6746\n",
      "Epoch 58 Batch 600 Loss 1.4356 Accuracy 0.6749\n",
      "Epoch 58 Batch 700 Loss 1.4115 Accuracy 0.6751\n",
      "Epoch 58 Batch 800 Loss 1.3922 Accuracy 0.6754\n",
      "Epoch 58 Loss 1.3839 Accuracy 0.6755\n",
      "Time taken for 1 epoch: 198.7999565601349 secs\n",
      "\n",
      "Epoch 59 Batch 0 Loss 1.8394 Accuracy 0.6755\n",
      "Epoch 59 Batch 100 Loss 1.5548 Accuracy 0.6756\n",
      "Epoch 59 Batch 200 Loss 1.5269 Accuracy 0.6758\n",
      "Epoch 59 Batch 300 Loss 1.4994 Accuracy 0.6760\n",
      "Epoch 59 Batch 400 Loss 1.4793 Accuracy 0.6761\n",
      "Epoch 59 Batch 500 Loss 1.4525 Accuracy 0.6764\n",
      "Epoch 59 Batch 600 Loss 1.4252 Accuracy 0.6766\n",
      "Epoch 59 Batch 700 Loss 1.4026 Accuracy 0.6769\n",
      "Epoch 59 Batch 800 Loss 1.3851 Accuracy 0.6771\n",
      "Epoch 59 Loss 1.3770 Accuracy 0.6772\n",
      "Time taken for 1 epoch: 199.07404255867004 secs\n",
      "\n",
      "Epoch 60 Batch 0 Loss 1.8047 Accuracy 0.6772\n",
      "Epoch 60 Batch 100 Loss 1.5566 Accuracy 0.6774\n",
      "Epoch 60 Batch 200 Loss 1.5248 Accuracy 0.6775\n",
      "Epoch 60 Batch 300 Loss 1.4935 Accuracy 0.6777\n",
      "Epoch 60 Batch 400 Loss 1.4740 Accuracy 0.6779\n",
      "Epoch 60 Batch 500 Loss 1.4477 Accuracy 0.6781\n",
      "Epoch 60 Batch 600 Loss 1.4192 Accuracy 0.6783\n",
      "Epoch 60 Batch 700 Loss 1.3956 Accuracy 0.6786\n",
      "Epoch 60 Batch 800 Loss 1.3777 Accuracy 0.6788\n",
      "Saving checkpoint for epoch 60 at checkpoints/ckpt-26\n",
      "Epoch 60 Loss 1.3689 Accuracy 0.6789\n",
      "Time taken for 1 epoch: 199.7579026222229 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss.reset_states()\n",
    "  \n",
    "    for (batch, (inp, tar)) in enumerate(dataset):\n",
    "        train_step(inp, tar)\n",
    "    \n",
    "        if batch % 100 == 0:\n",
    "            print(f'Epoch {epoch + 1} Batch {batch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
    "      \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1, ckpt_save_path))\n",
    "   \n",
    "    print(f'Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
    "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T19:43:57.013532Z",
     "iopub.status.busy": "2023-11-13T19:43:57.013193Z",
     "iopub.status.idle": "2023-11-13T19:43:57.023586Z",
     "shell.execute_reply": "2023-11-13T19:43:57.022554Z",
     "shell.execute_reply.started": "2023-11-13T19:43:57.013501Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(input_article):\n",
    "    input_article = article_tokenizer.texts_to_sequences([input_article])\n",
    "    input_article = tf.keras.preprocessing.sequence.pad_sequences(input_article, maxlen=ENCODER_LEN, \n",
    "                                                                   padding='post', truncating='post')\n",
    "\n",
    "    encoder_input = tf.expand_dims(input_article[0], 0)\n",
    "\n",
    "    decoder_input = [summary_tokenizer.word_index['<sos>']]\n",
    "    output = tf.expand_dims(decoder_input, 0)\n",
    "    \n",
    "    for i in range(DECODER_LEN):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, output)\n",
    "\n",
    "        predictions, attention_weights = transformer(\n",
    "            encoder_input, \n",
    "            output,\n",
    "            False,\n",
    "            enc_padding_mask,\n",
    "            combined_mask,\n",
    "            dec_padding_mask\n",
    "        )\n",
    "\n",
    "        predictions = predictions[: ,-1:, :]\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        if predicted_id == summary_tokenizer.word_index['<eos>']:\n",
    "            return tf.squeeze(output, axis=0), attention_weights\n",
    "\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output, axis=0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T19:48:40.158132Z",
     "iopub.status.busy": "2023-11-13T19:48:40.157764Z",
     "iopub.status.idle": "2023-11-13T19:48:40.163077Z",
     "shell.execute_reply": "2023-11-13T19:48:40.162059Z",
     "shell.execute_reply.started": "2023-11-13T19:48:40.158099Z"
    }
   },
   "outputs": [],
   "source": [
    "def summarize(input_article):\n",
    "    summarized = evaluate(input_article=input_article)[0].numpy()\n",
    "    summarized = np.expand_dims(summarized[1:], 0)  \n",
    "    return summary_tokenizer.sequences_to_texts(summarized)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions\n",
    "\n",
    "Below me make predictions on some texts to see how the model is performimg. Since this was a very basic approach the model wont perform that well but it can surely be improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T19:44:01.052930Z",
     "iopub.status.busy": "2023-11-13T19:44:01.052579Z",
     "iopub.status.idle": "2023-11-13T19:44:01.058906Z",
     "shell.execute_reply": "2023-11-13T19:44:01.058044Z",
     "shell.execute_reply.started": "2023-11-13T19:44:01.052901Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<SOS> A new trailer for the upcoming superhero film  Justice League  was released on Saturday. Based on the DC Comics superhero team, the film stars Ben Affleck as  Batman , Gal Gadot as  Wonder Woman , Ezra Miller as  The Flash  and Jason Momoa as  Aquaman . Directed by Zack Snyder, the film is scheduled to release on November 17, 2017. <EOS>'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T19:44:04.898508Z",
     "iopub.status.busy": "2023-11-13T19:44:04.898140Z",
     "iopub.status.idle": "2023-11-13T19:44:05.518865Z",
     "shell.execute_reply": "2023-11-13T19:44:05.517873Z",
     "shell.execute_reply.started": "2023-11-13T19:44:04.898476Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Headline :   New trailer of  Justice League  released  \n",
      " Predicted Summary :  new trailer of justice league released\n"
     ]
    }
   ],
   "source": [
    "print(\"Real Headline : \", summary[5][5:-5],\"\\n Predicted Summary : \", summarize(article[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T19:44:09.025304Z",
     "iopub.status.busy": "2023-11-13T19:44:09.024926Z",
     "iopub.status.idle": "2023-11-13T19:44:09.031110Z",
     "shell.execute_reply": "2023-11-13T19:44:09.030077Z",
     "shell.execute_reply.started": "2023-11-13T19:44:09.025269Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<SOS> As a part of an education initiative, the entire Wankhede Stadium will be reserved for underprivileged children for the IPL 2017 match between Mumbai Indians and Gujarat Lions, to be held on April 16. A statement by the Mumbai Indians read that they will not be selling any stand tickets for the team s third home game, against the Gujarat Lions. <EOS>'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T19:44:14.852674Z",
     "iopub.status.busy": "2023-11-13T19:44:14.852323Z",
     "iopub.status.idle": "2023-11-13T19:44:15.433048Z",
     "shell.execute_reply": "2023-11-13T19:44:15.432122Z",
     "shell.execute_reply.started": "2023-11-13T19:44:14.852641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Headline :   Underprivileged kids to fill Wankhede during MI s IPL match  \n",
      "Predicted Summary :  underprivileged kids to reserves in ipl match\n"
     ]
    }
   ],
   "source": [
    "print(\"Real Headline : \", summary[16][5:-5],\"\\nPredicted Summary : \", summarize(article[16]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
